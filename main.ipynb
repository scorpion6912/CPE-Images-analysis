{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sparqlwrapper in c:\\users\\aubry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in c:\\users\\aubry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sparqlwrapper) (7.0.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in c:\\users\\aubry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rdflib>=6.1.1->sparqlwrapper) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\aubry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rdflib>=6.1.1->sparqlwrapper) (3.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\aubry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->sparqlwrapper) (1.16.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\aubry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\aubry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aubry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aubry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aubry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aubry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.9.3-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting aiofiles\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: nest_asyncio in c:\\users\\aubry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aubry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp)\n",
      "  Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp)\n",
      "  Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\aubry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp) (3.6)\n",
      "Downloading aiohttp-3.9.3-cp312-cp312-win_amd64.whl (363 kB)\n",
      "   ---------------------------------------- 0.0/363.4 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 92.2/363.4 kB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 307.2/363.4 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 363.4/363.4 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.5/50.5 kB ? eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n",
      "Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.4/76.4 kB 4.1 MB/s eta 0:00:00\n",
      "Installing collected packages: multidict, frozenlist, aiofiles, yarl, aiosignal, aiohttp\n",
      "Successfully installed aiofiles-23.2.1 aiohttp-3.9.3 aiosignal-1.3.1 frozenlist-1.4.1 multidict-6.0.5 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install sparqlwrapper\n",
    "!pip install pandas\n",
    "%pip install aiohttp aiofiles nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd9571ed6434ec9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T10:32:29.983374Z",
     "start_time": "2024-03-05T10:32:29.977448Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.mkdir('images')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacb92f623e80c97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T07:36:40.923634Z",
     "start_time": "2024-03-06T07:36:22.697132Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# Get cities\n",
    "query = \"\"\"SELECT ?image WHERE {\n",
    "  ?item wdt:P31 wd:Q8502 . # Check if item is a mountain\n",
    "  ?item wdt:P18 ?image .\n",
    "}\n",
    "LIMIT 150\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (\n",
    "        sys.version_info[0],\n",
    "        sys.version_info[1],\n",
    "    )\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "def download_image(url):\n",
    "\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    request = requests.get(url, allow_redirects=True, headers=headers, stream=True)\n",
    "    if request.status_code == 200:\n",
    "        nom = os.path.basename(url)[-35:]\n",
    "        chemin = \"images/\"+nom\n",
    "        with open(chemin, \"wb\") as image:\n",
    "            request.raw.decode_content = True\n",
    "            shutil.copyfileobj(request.raw, image)\n",
    "    return request.status_code\n",
    "\n",
    "array = []\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    array.append(\n",
    "        (\n",
    "            result[\"image\"][\"value\"],\n",
    "        )\n",
    "    )\n",
    "    \n",
    "dataframe = pd.DataFrame(array, columns=[\"image\"])\n",
    "dataframe = dataframe.astype(\n",
    "    dtype={\"image\": \"<U200\"}\n",
    ")\n",
    "dataframe.image.apply(download_image)\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39bdceff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image: ./images\\%20Crater%20Lake%20%28052005%29.jpg\n",
      "Error processing image: ./images\\%20geograph.org.uk%20-%20958044.jpg\n",
      "Error processing image: ./images\\0de%20la%20Barre%20des%20Ecrins.png\n",
      "Error processing image: ./images\\0do%20Monte%20Roraima%20%281%29.jpg\n",
      "Error processing image: ./images\\20Gabelhorn%20und%20Wellenkuppe.jpg\n",
      "Error processing image: ./images\\20geograph.org.uk%20-%201247806.jpg\n",
      "Error processing image: ./images\\20geograph.org.uk%20-%201456731.jpg\n",
      "Error processing image: ./images\\20geograph.org.uk%20-%201457518.jpg\n",
      "Error processing image: ./images\\20geograph.org.uk%20-%201657454.jpg\n",
      "Error processing image: ./images\\31MonteGeneroso.jpg\n",
      "Error processing image: ./images\\AiguilleduGeant0001.jpg\n",
      "Error processing image: ./images\\AiguillesPeuterey0002.jpg\n",
      "Error processing image: ./images\\Allalinhorn0001.jpg\n",
      "Error processing image: ./images\\Bos%20Fulen.jpg\n",
      "Error processing image: ./images\\Bur%20ni%20Telong.jpg\n",
      "Error processing image: ./images\\Drus-verte.jpg\n",
      "Error processing image: ./images\\estseite%20gesehenVomGornergrat.JPG\n",
      "Error processing image: ./images\\GrandesJorasses0001a.jpg\n",
      "Error processing image: ./images\\Grivola0001.jpg\n",
      "Error processing image: ./images\\iz%20Alv%20%28Val%20Maighels%29.jpg\n",
      "Error processing image: ./images\\Lauteraarhorn.jpg\n",
      "Error processing image: ./images\\Lenzspitze.jpg\n",
      "Error processing image: ./images\\MayonVolcano.jpg\n",
      "Error processing image: ./images\\Mbcourmayeur0001.jpg\n",
      "Error processing image: ./images\\Monte%20Rosa%20-%20Castor.jpg\n",
      "Error processing image: ./images\\Monte%20Rosa%20-%20Corno%20Nero.jpg\n",
      "Error processing image: ./images\\Monte%20Rosa%20-%20Pollux.jpg\n",
      "Error processing image: ./images\\Monviso001.jpg\n",
      "Error processing image: ./images\\Nadelhorn%20shadows.jpg\n",
      "Error processing image: ./images\\Nadelhorn.jpg\n",
      "Error processing image: ./images\\Picswiss%20UR-38-52.jpg\n",
      "Error processing image: ./images\\Pilatus%20%28mountain%29.JPG\n",
      "Error processing image: ./images\\PiramideVincent0001.jpg\n",
      "Error processing image: ./images\\Punta%20Parrot0002.jpg\n",
      "Error processing image: ./images\\Rheinwaldhorn0001.jpg\n",
      "Error processing image: ./images\\scherhorn%20and%20Gr%C3%BCnhorn.jpg\n",
      "Error processing image: ./images\\SSR-Tajikistan-Peak%20Communism.jpg\n",
      "Error processing image: ./images\\Tandikat-Singgalang.jpg\n",
      "Error processing image: ./images\\Titlis%20view.jpg\n",
      "Error processing image: ./images\\TitlisgletscherWinter.jpg\n",
      "Error processing image: ./images\\TitlisVonSchoneggGesehen.jpg\n",
      "Error processing image: ./images\\tock%20Luftaufnahme%202012%2010.jpg\n",
      "Error processing image: ./images\\Triglav.jpg\n",
      "Error processing image: ./images\\Turtmanngletscher.jpg\n",
      "Error processing image: ./images\\Wallis%20Rimpfischhorn%20mg-k.jpg\n",
      "Error processing image: ./images\\Weisshorn.jpg\n",
      "Error processing image: ./images\\Witenwasserenstock.jpg\n",
      "Image metadata saved to: image_metadata.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image, ExifTags, TiffImagePlugin\n",
    "\n",
    "def extract_metadata(image_path):\n",
    "  \"\"\"\n",
    "  Extracts metadata from a single image.\n",
    "\n",
    "  Args:\n",
    "      image_path: Path to the image file.\n",
    "\n",
    "  Returns:\n",
    "      A dictionary containing the extracted metadata.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    image = Image.open(image_path)\n",
    "    exif_data = image._getexif()\n",
    "    metadata = dict()\n",
    "    for key, value in exif_data.items():\n",
    "      if isinstance(value, bytes):\n",
    "        continue\n",
    "      if (not isinstance(value, int)) and (not isinstance(value, float)):\n",
    "        value = f\"{value}\"\n",
    "      if key in ExifTags.TAGS:\n",
    "        metadata[ExifTags.TAGS[key]] = value\n",
    "    return metadata\n",
    "  except:\n",
    "    print(f\"Error processing image: {image_path}\")\n",
    "    return {}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Extracts metadata from all images in a folder and saves it to a JSON file.\n",
    "\"\"\"\n",
    "# Modify this path to your desired directory containing images\n",
    "image_dir = \"./images\"\n",
    "\n",
    "all_metadata = []\n",
    "for filename in os.listdir(image_dir):\n",
    "  if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "    metadata = extract_metadata(image_path)\n",
    "    all_metadata.append(metadata)\n",
    "\n",
    "# Modify this filename to your desired output file name\n",
    "output_file = \"image_metadata.json\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "  json.dump(all_metadata, f, indent=4)\n",
    "\n",
    "print(f\"Image metadata saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>itemLabel</th>\n",
       "      <th>image</th>\n",
       "      <th>partLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q513</td>\n",
       "      <td>Everest</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>Himalaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q513</td>\n",
       "      <td>Everest</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>sommets de plus de huit mille mètres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q513</td>\n",
       "      <td>Everest</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>sept sommets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.wikidata.org/entity/Q513</td>\n",
       "      <td>Everest</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>sommet ultra-proéminent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.wikidata.org/entity/Q583</td>\n",
       "      <td>mont Blanc</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>sept sommets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>http://www.wikidata.org/entity/Q122225</td>\n",
       "      <td>Seongsan Ilchulbong</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>île volcanique et tunnels de lave de Jeju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>http://www.wikidata.org/entity/Q122225</td>\n",
       "      <td>Seongsan Ilchulbong</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>île volcanique et tunnels de lave de Jeju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>http://www.wikidata.org/entity/Q125156</td>\n",
       "      <td>Alutu</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>vallée du grand rift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>http://www.wikidata.org/entity/Q542041</td>\n",
       "      <td>mont Townsend</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>Sept seconds sommets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>http://www.wikidata.org/entity/Q542505</td>\n",
       "      <td>Hohenstaufen</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>Q1257054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       qid            itemLabel  \\\n",
       "0      http://www.wikidata.org/entity/Q513              Everest   \n",
       "1      http://www.wikidata.org/entity/Q513              Everest   \n",
       "2      http://www.wikidata.org/entity/Q513              Everest   \n",
       "3      http://www.wikidata.org/entity/Q513              Everest   \n",
       "4      http://www.wikidata.org/entity/Q583           mont Blanc   \n",
       "..                                     ...                  ...   \n",
       "95  http://www.wikidata.org/entity/Q122225  Seongsan Ilchulbong   \n",
       "96  http://www.wikidata.org/entity/Q122225  Seongsan Ilchulbong   \n",
       "97  http://www.wikidata.org/entity/Q125156                Alutu   \n",
       "98  http://www.wikidata.org/entity/Q542041        mont Townsend   \n",
       "99  http://www.wikidata.org/entity/Q542505         Hohenstaufen   \n",
       "\n",
       "                                                image  \\\n",
       "0   http://commons.wikimedia.org/wiki/Special:File...   \n",
       "1   http://commons.wikimedia.org/wiki/Special:File...   \n",
       "2   http://commons.wikimedia.org/wiki/Special:File...   \n",
       "3   http://commons.wikimedia.org/wiki/Special:File...   \n",
       "4   http://commons.wikimedia.org/wiki/Special:File...   \n",
       "..                                                ...   \n",
       "95  http://commons.wikimedia.org/wiki/Special:File...   \n",
       "96  http://commons.wikimedia.org/wiki/Special:File...   \n",
       "97  http://commons.wikimedia.org/wiki/Special:File...   \n",
       "98  http://commons.wikimedia.org/wiki/Special:File...   \n",
       "99  http://commons.wikimedia.org/wiki/Special:File...   \n",
       "\n",
       "                                    partLabel  \n",
       "0                                    Himalaya  \n",
       "1        sommets de plus de huit mille mètres  \n",
       "2                                sept sommets  \n",
       "3                     sommet ultra-proéminent  \n",
       "4                                sept sommets  \n",
       "..                                        ...  \n",
       "95  île volcanique et tunnels de lave de Jeju  \n",
       "96  île volcanique et tunnels de lave de Jeju  \n",
       "97                       vallée du grand rift  \n",
       "98                       Sept seconds sommets  \n",
       "99                                   Q1257054  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "import aiofiles\n",
    "import aiohttp\n",
    "from pandas import DataFrame\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# Get mountains\n",
    "query = \"\"\"\n",
    "    SELECT ?item ?itemLabel ?part ?partLabel ?image WHERE {\n",
    "      ?item wdt:P31 wd:Q8502 .\n",
    "      ?item wdt:P361 ?part .\n",
    "      ?item wdt:P18 ?image .\n",
    "\n",
    "    SERVICE wikibase:label { #BabelRainbow\n",
    "        bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],fr\"\n",
    "    }\n",
    "\n",
    "    }\n",
    "    LIMIT 100\n",
    "\"\"\"\n",
    "nest_asyncio.apply()\n",
    "\n",
    "download_sem = asyncio.Semaphore(4)\n",
    "\n",
    "async def download_images(df: DataFrame):\n",
    "    download_tasks = []\n",
    "    print(f\"Téléchargement de {len(df)} images...\")\n",
    "    for _, row in df.iterrows():\n",
    "        url = row[\"image\"]\n",
    "        download_tasks.append(download_image(url))\n",
    "    await asyncio.gather(*download_tasks)\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (\n",
    "        sys.version_info[0],\n",
    "        sys.version_info[1],\n",
    "    )\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "async def download_image(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "            async with download_sem:\n",
    "                async with session.get(url, allow_redirects=True, headers=headers) as res:\n",
    "                    if res.status != 200:\n",
    "                        print(f\"Impossible de télécharger l'image à l'url {url} (code {res.status})\")\n",
    "                        return\n",
    "                    nom = os.path.basename(url)[-35:]\n",
    "                    chemin = \"images/\"+nom\n",
    "                    async with aiofiles.open(f\"{chemin}\", \"wb\") as f:\n",
    "                        await f.write(await res.read())\n",
    "                        await f.close()\n",
    "\n",
    "array = []\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    element = []\n",
    "    element.append(result[\"item\"][\"value\"])\n",
    "    element.append(result[\"itemLabel\"][\"value\"])\n",
    "    element.append(result[\"image\"][\"value\"])\n",
    "    element.append(result[\"partLabel\"][\"value\"])\n",
    "    array.append(element)\n",
    "    \n",
    "dataframe = pd.DataFrame(array, columns=[\"qid\", \"itemLabel\", \"image\", \"partLabel\"])\n",
    "\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement de 100 images...\n"
     ]
    }
   ],
   "source": [
    "asyncio.run(download_images(dataframe))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

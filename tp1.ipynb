{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T08:01:51.855518Z",
     "start_time": "2024-03-05T08:01:51.631924Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T08:51:56.226866900Z",
     "start_time": "2024-02-14T08:51:56.187042400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "dataset = np.loadtxt(\n",
    "    \"DataMining/data/pl.csv\",  # Remplacez cette valeur par le chemin d'accès de votre fichier CSV.\n",
    "    dtype={\"names\": (\"name\", \"year\"), \"formats\": (\"U100\", \"i4\")},\n",
    "    skiprows=1,  # passez la première ligne, puisque c'est l'en-tête\n",
    "    delimiter=\",\",  # le séparateur est une virgule puisqu'il s'agit d'un fichier CSV.\n",
    "    encoding=\"UTF-8\",  # encodage UTF-8\n",
    ")\n",
    "print(len(dataset))\n",
    "\n",
    "dataset = np.loadtxt(\n",
    "    \"DataMining/data/pl.tsv\",  # Remplacez cette valeur par le chemin d'accès de votre fichier TSV.\n",
    "    dtype={\"names\": (\"name\", \"year\"), \"formats\": (\"U100\", \"i4\")},\n",
    "    skiprows=1,\n",
    "    delimiter=\"\\t\",  # le séparateur est '\\t' puisqu'il s'agit d'un fichier TSV.\n",
    "    encoding=\"UTF-8\",\n",
    ")\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T08:55:56.216080600Z",
     "start_time": "2024-02-14T08:55:56.095570700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year                              languageLabel\n",
      "0   1942                                 Plankalkül\n",
      "1   1943                        ENIAC coding system\n",
      "2   1946                           ENIAC Short Code\n",
      "3   1946  Von Neumann and Goldstine graphing system\n",
      "4   1948                          CPC Coding scheme\n",
      "..   ...                                        ...\n",
      "95  1967                                       BCPL\n",
      "96  1967                 Space Programming Language\n",
      "97  1968                                       CICS\n",
      "98  1968                                      FOCAL\n",
      "99  1968                                      Refal\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "url = \"https://query.wikidata.org/sparql?query=SELECT%20%3FlanguageLabel%20(YEAR(%3Finception)%20as%20%3Fyear)%0AWHERE%0A%7B%0A%20%20%23instances%20of%20programming%20language%0A%20%20%3Flanguage%20wdt%3AP31%20wd%3AQ9143%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20wdt%3AP571%20%3Finception%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20rdfs%3Alabel%20%3FlanguageLabel.%0A%20%20FILTER(lang(%3FlanguageLabel)%20%3D%20%22en%22)%0A%7D%0AORDER%20BY%20%3Fyear%0ALIMIT%20100&format=json\"\n",
    "response = urllib.request.urlopen(url)\n",
    "responsedata = json.loads(response.read().decode(\"utf-8\"))\n",
    "\n",
    "array = []\n",
    "\n",
    "for data in responsedata[\"results\"][\"bindings\"]:\n",
    "    array.append([data[\"year\"][\"value\"], data[\"languageLabel\"][\"value\"]])\n",
    "\n",
    "dataframe = pd.DataFrame(array, columns=[\"year\", \"languageLabel\"])\n",
    "dataframe = dataframe.astype(dtype={\"year\": \"<i4\", \"languageLabel\": \"<U200\"})\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercice 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                            languageLabel\n                                                    count\nyear paradigmLabel                                       \n1948 procedural programming                             1\n1949 non-structured programming                         1\n     procedural programming                             1\n1950 procedural programming                             1\n1953 procedural programming                             1\n...                                                   ...\n1970 imperative programming                             1\n     procedural programming                             1\n     structured programming                             1\n1971 functional programming                             1\n     knowledge representation and reasoning             1\n\n[73 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>languageLabel</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>year</th>\n      <th>paradigmLabel</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1948</th>\n      <th>procedural programming</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">1949</th>\n      <th>non-structured programming</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>procedural programming</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1950</th>\n      <th>procedural programming</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1953</th>\n      <th>procedural programming</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1970</th>\n      <th>imperative programming</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>procedural programming</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>structured programming</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">1971</th>\n      <th>functional programming</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>knowledge representation and reasoning</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>73 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import json_normalize\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "jsondata = json.load(open(\"DataMining/data/plparadigm.json\"))\n",
    "array = []\n",
    "\n",
    "for data in jsondata:\n",
    "    array.append([data[\"year\"], data[\"languageLabel\"], data[\"paradigmLabel\"]])\n",
    "\n",
    "dataframe = pd.DataFrame(array, columns=[\"year\", \"languageLabel\", \"paradigmLabel\"])\n",
    "dataframe = dataframe.astype(\n",
    "    dtype={\"year\": \"int64\", \"languageLabel\": \"<U200\", \"paradigmLabel\": \"<U200\"}\n",
    ")\n",
    "\n",
    "grouped = dataframe.groupby([\"year\", \"paradigmLabel\"]).agg([\"count\"])\n",
    "grouped\n",
    "\n",
    "# grouped = dataframe.groupby([\"paradigmLabel\", \"year\"]).agg([\"count\"])\n",
    "# grouped"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T09:01:06.291195500Z",
     "start_time": "2024-02-14T09:01:06.276539700Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population des pays dans l'ordre alphabétique de leur nom et par ordre croissant d'année :\n",
      "          year countryLabel  population\n",
      "0   1960-01-01  Afghanistan     8774440\n",
      "1   1961-01-01  Afghanistan     8953544\n",
      "2   1962-01-01  Afghanistan     9141783\n",
      "3   1963-01-01  Afghanistan     9339507\n",
      "4   1964-01-01  Afghanistan     9547131\n",
      "..         ...          ...         ...\n",
      "995 2007-01-01      Bolivia     9676456\n",
      "996 2008-01-01      Bolivia     9834098\n",
      "997 2009-01-01      Bolivia     9993406\n",
      "998 2010-01-01      Bolivia    10156601\n",
      "999 2011-01-01      Bolivia    10324445\n",
      "\n",
      "[1000 rows x 3 columns]\n",
      "Pays avec la population la plus faible : Andorra\n",
      "Pays avec la population la plus élevée : Bangladesh\n"
     ]
    }
   ],
   "source": [
    "from pandas import json_normalize\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Charger les données JSON\n",
    "jsondata = json.load(open(\"countrydata.json\"))\n",
    "array = []\n",
    "\n",
    "# Extraire les données nécessaires\n",
    "for data in jsondata:\n",
    "    array.append([data[\"year\"], data[\"countryLabel\"], data[\"population\"]])\n",
    "\n",
    "# Créer un DataFrame\n",
    "dataframe = pd.DataFrame(array, columns=[\"year\", \"countryLabel\", \"population\"])\n",
    "\n",
    "# Convertir les types de données appropriés\n",
    "dataframe[\"year\"] = pd.to_datetime(dataframe[\"year\"], format='%Y')\n",
    "dataframe[\"population\"] = pd.to_numeric(dataframe[\"population\"])\n",
    "\n",
    "# Trier le DataFrame par ordre alphabétique de pays et année croissante\n",
    "dataframe.sort_values(by=[\"countryLabel\", \"year\"], inplace=True)\n",
    "\n",
    "# Afficher la population des pays dans l'ordre alphabétique de leur nom et par ordre croissant d'année\n",
    "print(\"Population des pays dans l'ordre alphabétique de leur nom et par ordre croissant d'année :\")\n",
    "print(dataframe)\n",
    "\n",
    "# Obtenir la dernière population disponible de chaque pays\n",
    "latest_population = dataframe.groupby('countryLabel')['population'].last().reset_index()\n",
    "\n",
    "# Identifier le pays avec la population la plus faible et la plus élevée (la plus récente)\n",
    "min_population_country = latest_population.loc[latest_population['population'].idxmin()]['countryLabel']\n",
    "max_population_country = latest_population.loc[latest_population['population'].idxmax()]['countryLabel']\n",
    "\n",
    "# Afficher le pays avec la population la plus faible et la plus élevée\n",
    "print(f\"Pays avec la population la plus faible : {min_population_country}\")\n",
    "print(f\"Pays avec la population la plus élevée : {max_population_country}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T10:00:14.806079200Z",
     "start_time": "2024-02-14T10:00:14.777767600Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre d'articles publiés sur différents sujets chaque année :     year subjectLabel  Nombre d'articles\n",
      "0   2011        Earth                 65\n",
      "1   2011     Universe                 34\n",
      "2   2012        Earth                 34\n",
      "3   2012     Universe                 41\n",
      "4   2013        Earth                 38\n",
      "5   2013     Universe                 34\n",
      "6   2014        Earth                 69\n",
      "7   2014     Universe                 65\n",
      "8   2015        Earth                 64\n",
      "9   2015     Universe                 55\n",
      "10  2015        death                  1\n",
      "11  2016        Earth                 66\n",
      "12  2016     Universe                 47\n",
      "13  2017        Earth                 48\n",
      "14  2017     Universe                 38\n",
      "15  2018        Earth                 50\n",
      "16  2018     Universe                 31\n",
      "17  2019        Earth                 38\n",
      "18  2019     Universe                 41\n",
      "19  2020        Earth                 19\n",
      "20  2020     Universe                 24\n",
      "21  2021        Earth                 20\n",
      "22  2021     Universe                 26\n",
      "23  2022        Earth                 21\n",
      "24  2022     Universe                 27\n",
      "25  2023        Earth                  1\n",
      "26  2023     Universe                  2\n",
      "27  2024     Universe                  1\n",
      "Principal sujet d'intérêt :     year subjectLabel  Nombre d'articles\n",
      "6   2014        Earth                 69\n",
      "11  2016        Earth                 66\n",
      "0   2011        Earth                 65\n",
      "8   2015        Earth                 64\n",
      "15  2018        Earth                 50\n",
      "13  2017        Earth                 48\n",
      "18  2019     Universe                 41\n",
      "3   2012     Universe                 41\n",
      "4   2013        Earth                 38\n",
      "24  2022     Universe                 27\n",
      "22  2021     Universe                 26\n",
      "20  2020     Universe                 24\n",
      "26  2023     Universe                  2\n",
      "27  2024     Universe                  1\n",
      "Les 10 principaux sujets d'intérêt : subjectLabel\n",
      "Universe    14\n",
      "Earth       13\n",
      "death        1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier JSON\n",
    "data = pd.read_json(\"scienceData.json\")\n",
    "\n",
    "# Créer un DataFrame regroupé par sujet et année\n",
    "df_annee_sujet = data.groupby([\"year\", \"subjectLabel\"]).size().reset_index(name=\"Nombre d'articles\")\n",
    "\n",
    "# Afficher le résultat\n",
    "print(f\"Le nombre d'articles publiés sur différents sujets chaque année : {df_annee_sujet.to_string()}\")\n",
    "\n",
    "# Trouver le sujet avec le nombre d'articles le plus élevé pour chaque année\n",
    "df_sujet_principal_annee = df_annee_sujet.sort_values(\"Nombre d'articles\", ascending=False).groupby(\"year\").head(1)\n",
    "\n",
    "# Afficher le résultat\n",
    "print(f\"Principal sujet d'intérêt : {df_sujet_principal_annee.to_string()}\")\n",
    "\n",
    "# Filtrer les données depuis 2010\n",
    "df_depuis_2010 = df_annee_sujet[df_annee_sujet[\"year\"] >= 2010]\n",
    "\n",
    "# Compter le nombre d'articles par sujet\n",
    "df_top_10_sujets = df_depuis_2010.groupby(\"subjectLabel\").size().sort_values(ascending=False).head(10)\n",
    "\n",
    "# Afficher le résultat\n",
    "print(f\"Les 10 principaux sujets d'intérêt : {df_top_10_sujets.to_string()}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T10:18:23.305950600Z",
     "start_time": "2024-02-14T10:18:23.285935200Z"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercice 6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        ville           pays  \\\n0      Erevan        Arménie   \n1    Helsinki       Finlande   \n2       Pskov         Russie   \n3  Copenhague       Danemark   \n4      Québec         Canada   \n5        Pune           Inde   \n6      Riazan         Russie   \n7      Erfurt      Allemagne   \n8      Djouba  Soudan du Sud   \n9    Edmonton         Canada   \n\n                                               image  \n0  http://commons.wikimedia.org/wiki/Special:File...  \n1  http://commons.wikimedia.org/wiki/Special:File...  \n2  http://commons.wikimedia.org/wiki/Special:File...  \n3  http://commons.wikimedia.org/wiki/Special:File...  \n4  http://commons.wikimedia.org/wiki/Special:File...  \n5  http://commons.wikimedia.org/wiki/Special:File...  \n6  http://commons.wikimedia.org/wiki/Special:File...  \n7  http://commons.wikimedia.org/wiki/Special:File...  \n8  http://commons.wikimedia.org/wiki/Special:File...  \n9  http://commons.wikimedia.org/wiki/Special:File...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ville</th>\n      <th>pays</th>\n      <th>image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Erevan</td>\n      <td>Arménie</td>\n      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Helsinki</td>\n      <td>Finlande</td>\n      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pskov</td>\n      <td>Russie</td>\n      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Copenhague</td>\n      <td>Danemark</td>\n      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Québec</td>\n      <td>Canada</td>\n      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Pune</td>\n      <td>Inde</td>\n      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Riazan</td>\n      <td>Russie</td>\n      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Erfurt</td>\n      <td>Allemagne</td>\n      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Djouba</td>\n      <td>Soudan du Sud</td>\n      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Edmonton</td>\n      <td>Canada</td>\n      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# Get cities\n",
    "query = \"\"\"SELECT DISTINCT ?grandeville ?grandevilleLabel ?pays ?paysLabel ?image {\n",
    "  ?grandeville wdt:P31 wd:Q1549591;\n",
    "               wdt:P17 ?pays;\n",
    "               wdt:P18 ?image.\n",
    " SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr\". }\n",
    "}\n",
    "LIMIT 10\"\"\"\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (\n",
    "        sys.version_info[0],\n",
    "        sys.version_info[1],\n",
    "    )\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "def download_image(url):\n",
    "\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    request = requests.get(url, allow_redirects=True, headers=headers, stream=True)\n",
    "    if request.status_code == 200:\n",
    "        with open(os.path.basename(url), \"wb\") as image:\n",
    "            request.raw.decode_content = True\n",
    "            shutil.copyfileobj(request.raw, image)\n",
    "    return request.status_code\n",
    "\n",
    "array = []\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    array.append(\n",
    "        (\n",
    "            result[\"grandevilleLabel\"][\"value\"],\n",
    "            result[\"paysLabel\"][\"value\"],\n",
    "            result[\"image\"][\"value\"],\n",
    "        )\n",
    "    )\n",
    "    \n",
    "dataframe = pd.DataFrame(array, columns=[\"ville\", \"pays\", \"image\"])\n",
    "dataframe = dataframe.astype(\n",
    "    dtype={\"ville\": \"<U200\", \"pays\": \"<U200\", \"image\": \"<U200\"}\n",
    ")\n",
    "dataframe.image.apply(download_image)\n",
    "\n",
    "dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:04:49.771303Z",
     "start_time": "2024-03-05T08:04:21.695495Z"
    }
   },
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
